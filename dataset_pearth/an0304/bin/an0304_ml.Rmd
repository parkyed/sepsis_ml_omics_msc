---
title: "deseq2+mlseq, normalisation and transformation"
author: "Robert Andrews + Ed Parkinson"
date: "22/11/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

The input data is accompanied by a file called targets_ml.csv, containing patient ID and their groups, with an additional column that combines all controls togetner (N-LOS, INDEX and contaminant). Clinical sepsis (P-LOS) may be removed from the analysis subsequently.

Groups labels are:
C-LOS - confirmed bacterial sepsis
P-lOS - possible sepsis / clinical sepsis
N-LOS - controls
INDEX - control, some paried to patients who subsequently became septic
Contaminant - infection deemed to be due to contamination on the line => consider as controls

The code below performs required data pre-processing, normalisation and transformation for input into machine learning models designed to identify genes that discriminate between sepsis and controls

Normalisation methods:

1. DEseq2 'median of ratios' - controls for sequence depth / library size (total number of reads for the sample) and sample composition (proportion of mRNA accounted for by a given gene), using a median of the ratios of read count to the geometric mean of all read counts. Used as a scaling factor for that sample.
- calculate geometric average read (average of natural log of reads) for each gene
- remove genes with infinity as avg => that not transcribed in some samples (in theory helps focus the scaling on the housekeeping genes, those transcribed at similar levels)
- subtract the geometric average for the gene from the log of each count for the gene (makes the first three steps equivalent to taking log of read over avg. read for each gene). This is an indication of over / under expression, since compares read to avearge. Taking the log diminishes the impact of outliers.
- find median of the ratio of log (read / average) for each sample. Again median, diminishes impact of highly over / underexpressed genes on the scaling factor. Since highly expressed genes rare, this again gives more influence on the scaling factor to genes with moderate differences, i.e. housekeeping genes.
- convert the medians back to normal number (i.e. raise e to power of the number) to get final scaling factors for each sample
- divide the original read counts by the scaling factors for each sample respecively
source: https://www.youtube.com/watch?v=UFB993xufUU 
- sequence depth variation - difficult to control how much sample you put in the machine

2. CPM - 'counts per million' - counts scaled by total number of reads. Controls for sequence depth/ library size, but not sample composition.
2. FPKM (fragments per kilobase of exon per million fragments mapped) - controls for sequence depth / library size and gene length, BUT NOT FOR SAMPLE COMPOSITION => BIASED BETWEEN SAMPLE COMPARISONS (https://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/)
4. EdgeR - 'trimmed mean of M values (TMM)' - controls for sequence depth, sample composition. Similar to 'median of ratios'.

Transformations:
1. vst- 'variance stabilising transformation' - ensure homoscedasticity, required for some models (but not assumed by LR, SVM, Tree-based)

Questions:

Is DESeq2 median of ratios sufficient to control for library size and sample composition? Is TMM better?
Do I need to normalise for gene length, since not doing within sample comparison, and will z-score all features?
Is the total amount of mRNA / cell assumed to be the same across samples and conditions? Could all genes be more highly expressed in one condition?
Is vst going to add anything since my models don't assume homoscedasticity?
What are the right filters to get rid of noise, esp. if not using fpkm values? Could still use as a filter, even if not using downstream?

Next steps:

Then need to add ensembl ID into previous data and test all in python
Other packages - edgeR (from the micro array people), limaVOOM (does CPM). DESeq2 is from Huber (gugu)

```{r}

setwd("/Users/Ed/Documents/GitHub/sepsis_ml_omics_msc/dataset_pearth/an0304/bin")

#countInputFiles <- c("all.markdup.genecount", "all.rmdup.genecount")
countInputFiles <- c("all.markdup.genecount")

#Coefficient of Variation = (Standard Deviation / Mean) * 100
## https://www.statology.org/coefficient-of-variation-in-r/
coefficientOfVariationCutoff <- 10

#fpkmCountfilters <- c("nofilter", 0, 0.5, 5, 10)
fpkmCountfilters <- c(0.5)

```

Load relevant libraries

```{r}

library(DESeq2)     # differential analysis
library(MLseq)      # pre-processing and transformations for ML, and ML functions

library(ape)        # clustering QC
library(ggplot2)    # PCA plotting
library(ggrepel)

library(dplyr)      # data manipulations
library(docstring)  # docstring information

```

Create the uber input counts files

Read in all data

```{r}

## get top, middle and bottom

rawDataTop <- read.table("../input/top/all.markdup.genecount.txt", sep="\t", header=T, check.names=F)
rawDataMiddle <- read.table("../input/middle/all.markdup.genecount.txt", sep="\t", header=T, check.names=F)
rawDataBottom <- read.table("../input/bottom/all.markdup.genecount.txt", sep="\t", header=T, check.names=F)

## get the topups

rawDataTopups <- read.table("../input/topups/all.markdup.genecount.txt", sep="\t", header=T, check.names=F)

```

merge top, middle and bottom

```{r}

rawData <- merge(rawDataTop, rawDataMiddle, by="ensemblGeneID")

rawData <-  dplyr::select(rawData, -geneLength.y, -geneName.y, -geneBiotype.y)
colnames(rawData)[2:4] <- c("geneLength", "geneName", "geneBiotype")

rawData <- merge(rawData, rawDataBottom, by="ensemblGeneID")

rawData <-  dplyr::select(rawData, -geneLength.y, -geneName.y, -geneBiotype.y)
colnames(rawData)[2:4] <- c("geneLength", "geneName", "geneBiotype")

```

merge top-ups into raw data

```{r}

## get a list of merged samples - empty vector

replacedups <- c()

## paranoia check: are the order of genes the same in the tops and the top-ups??

if (all(rawData$ensemblGeneID != rawDataTopups$ensemblGeneID)) { stop() }

mergedRawData <- rawData

for (coln in colnames(dplyr::select(rawDataTopups, -ensemblGeneID, -geneLength, -geneName, -geneBiotype))) {
  
  # identify the matching column names in the merged raw data by string replacement as topup columns named differently
  oldColn <- gsub(".b", "", coln)
  oldColn <- gsub("NO_LOS", "NOLOS", oldColn)
  
  if (oldColn %in% colnames(mergedRawData)) {
    
    mergedRawData[oldColn] <- mergedRawData[oldColn] + rawDataTopups[coln]
    replacedups <- c(replacedups, oldColn)

  }
  
}

```

Check that all top-ups have been merged

```{r}

topupColnames <- gsub("NO_LOS", "NOLOS", gsub(".b", "", colnames(dplyr::select(rawDataTopups, -ensemblGeneID, -geneLength, -geneName, -geneBiotype))))

if (all(topupColnames != replacedups)) { stop() }

```

Write the raw counts to a master file in the uber input folder

```{r}

write.table(mergedRawData, file="../input/uber/all.markdup.genecount.txt", sep="\t", row.names = F, col.names = T, quote = F)

geneLengths <- dplyr::select(rawData, ensemblGeneID, geneLength)

```

======== end of merging and deduplicating of datasets ============

Define functions used to run the normalisations and transformations of the data

```{r}


RunDeseq2 <- function(rc, gl) {
    
    #' Generate analysis object
    #'
    #' Creates analysis object from table of raw counts and table of gene lengths
    #' @param rc The table of raw counts with ensembl_gene_ID as row index and patient sampel ID as column name
    #' @param gl The table of gene lengths
    
    ## create the experimental design object for DeSeq2.
    ## creates a dataframe with mapping of the sample id to the sample group
    
    exptDesign <- data.frame(
            row.names = colnames(rc),
            condition = sampleGroups)
    
    ## construct experiment object -object used to store input values, intermediate calculations and result of differential expression analysis
    ## takes as input the raw counts (pre-processed data), mapping of samples to groups, colData - rows correspond to the columns of the raw counts
    ## design specifies how the counts in countData depend on the variables in colData
    ## effectively does an ANOVA and looks at the impact of group membership on differential expression
    
    exptObject <- DESeqDataSetFromMatrix(
          countData = rc,
          colData = exptDesign,
          design = ~ condition)

    ## run the analysis
    ## returns matrix of ensembl gene ids with baseMean, log2foldchange, lfcSE, stat, p-value, padj
    ## this DESeq does a normalisation, generates scaling factors, scales by the total number of reads in each of the columns - READ DOCUMENTATION
    ## aim of the normalisation, puts each column (sample) on the same scale - scaling factor for the column
    ## different to microarrays that do a quantile normalisation
    ## if you run the results function without any other arguments, it runs an anova, and you get a list of the most significant genes
    ## if you run the results function with an argument (coefficient), e.g. P-Los, c-los, then you get a pairwise comparison
    ## to compare healthy vs. control, take the targets.csv and add another column and refernece in the exptDesign object
    analysisObject = DESeq(exptObject)

    ## add gene lengths to the analysis object for the FPKM calculation
    
    ## ensure that the ensembl gene ids match first
    geneLengthsTemp <- gl[gl$ensemblGeneID %in% rownames(analysisObject),]
    
    ## add in a $basepairs column to the analysis Object output - required for FPKM normalisation based on gene length
    mcols(analysisObject)$basepairs <- geneLengthsTemp[match(rownames(analysisObject), geneLengthsTemp$ensemblGeneID),]$geneLength
    
    return(analysisObject)    
}


DESeq_object <- function(rc, gl) {
    
    #' Generate analysis object
    #'
    #' Creates analysis object from table of raw counts and table of gene lengths
    #' @param rc The table of raw counts with ensembl_gene_ID as row index and patient sampel ID as column name
    #' @param gl The table of gene lengths
    
    ## create the experimental design object for DeSeq2.
    ## creates a dataframe with mapping of the sample id to the sample group
    
    exptDesign <- data.frame(
            row.names = colnames(rc),
            condition = sampleGroups)
    
    ## construct experiment object -object used to store input values, intermediate calculations and result of differential expression analysis
    ## takes as input the raw counts, mapping of samples to groups, colData - rows correspond to the columns of the raw counts
    ## design specifies how the counts in countData depend on the variables in colData

    exptObject <- DESeqDataSetFromMatrix(
          countData = rc,
          colData = exptDesign,
          design = ~ condition)

    ## add gene lengths to the analysis object for the FPKM calculation
    
    ## ensure that the ensembl gene ids match first
    geneLengthsTemp <- gl[gl$ensemblGeneID %in% rownames(exptObject),]
    
    ## add in a $basepairs column to the analysis Object output - required for FPKM normalisation based on gene length
    mcols(exptObject)$basepairs <- geneLengthsTemp[match(rownames(exptObject), geneLengthsTemp$ensemblGeneID),]$geneLength
    
    return(exptObject)    
}


vst_transform <- function(rc) {
    
    #' Perform variance stabilising transformation on input counts data
    #'
    #' Creates analysis object from table of raw counts
    #' @param rc The table of raw counts with ensembl_gene_ID as row index and patient sampel ID as column name
    
    ## create the experimental design object for DeSeq2.
    ## creates a dataframe with mapping of the sample id to the sample group
    
    exptDesign <- data.frame(
            row.names = colnames(rc),
            condition = sampleGroups)
    
    ## construct experiment object -object used to store input values, intermediate calculations and result of differential expression analysis
    ## takes as input the raw counts (pre-processed data), mapping of samples to groups, colData - rows correspond to the columns of the raw counts

    exptObject <- DESeqDataSetFromMatrix(
          countData = rc,
          colData = exptDesign,
          design = ~ condition)

    ## perform the transformations 
    
    vsd <- varianceStabilizingTransformation(exptObject, blind=FALSE)
    vsd <- assay(vsd)
    
    return(vsd)
}

```


=============  Normalise and filter raw data ready for ml input =============================


```{r}

## READ INPUT FILES 

## read targets file
targets <- read.table("../resources/targets.csv", sep=",", header=T)

## read input data file

rawCounts <- read.table(paste("../input/uber/all.markdup.genecount.txt", sep=""), sep="\t", header=TRUE, check.names=F)

## INPUT DATA PRE-PROCESSING

## remove outliers from input files

if (length(outliers) > 0) {
  
  # remove any rows from the targets table, where the sample id is in the outliers vector 
  targets <- targets[!targets$analysisID %in% outliers, ]
  
  # remove any columns from the rawCounts table (i.e. the merged raw data) where sample id is in the outliers vector
  rawCounts <- rawCounts[, !(names(rawCounts) %in% outliers)]
}

## remove any minus sign from the column names (not the case in current dataset)

colnames(rawCounts) <- sub("-", ".", colnames(rawCounts))

# parse out the 3 first columns of annotation

annotationNames <- rawCounts[,c(1:4)]

# get the sample groups from targets

sampleGroups <- targets$sampleGroupML

# add rownames to the raw data using ensembleGeneID as the index, and remove all four annotation columns

rownames(rawCounts) = rawCounts[,1]
rawCounts[,c(1:4)] <- NULL

## check the order of the targets files and input counts file are identical

if (!identical(as.character(targets$analysisID), colnames(rawCounts))) {
  rawCounts <- dplyr::select(rawCounts, as.character(targets$analysisID))
}
    
## RUN DEseq NORMALISATION WITHOUT FILTERING GENES

## create deseq dataset object from raw counts, and include gene lengths for fpkm, estimate size factors
analysisObject <- DESeq_object(rawCounts, geneLengths)
analysisObject_sf <- estimateSizeFactors(analysisObject)

##analysisObject <- RunDeseq2(rawCounts, geneLengths)
  
## extract raw, median-ratio normalised and fpkm normalised counts from the output, and check rows match

rawCounts <- counts(analysisObject_sf, normalized = FALSE)
normalisedCounts <- counts(analysisObject_sf, normalized = TRUE)
fpkmNormalisedCounts <- fpkm(analysisObject, robust = TRUE)

if (!identical(rownames(rawCounts), rownames(normalisedCounts))) { stop() }
if (!identical(rownames(fpkmNormalisedCounts), rownames(rawCounts))) { stop() }

## Filter genes based on minimum coefficient of variation over entire gene - exclude any gene where cov is less than threshold

cov <- apply(fpkmNormalisedCounts, 1, function(x) sd(x) / mean(x) * 100)

rawCountsToKeep <- rawCounts[cov >= coefficientOfVariationCutoff, ]

## filter the object by minimum fpkmNormalisedCounts then re run the DEseq on filtered data

if (countfilter != "nofilter") {
  
  ## exclude any gene where the fpkm normalised counts don't meet a minimum threshold for at least one gene. (note <0.5 indicates unclear if gene present)
  ## still filter on fpkm low, otherwise the filters will bia genes 
  ## reference: https://www.ebi.ac.uk/gxa/FAQ.html

  rawCountsToKeep <- rawCounts[rowSums(fpkmNormalisedCounts > countfilter) >= 1, ]
}

## RUN DEseq ANALYSIS WITH FILTERs

## analysisObject <- RunDeseq2(rawCountsToKeep, geneLengths)

analysisObject <- DESeq_object(rawCountsToKeep, geneLengths)
analysisObject_sf <- estimateSizeFactors(analysisObject)

## extract raw, scaling factor normalised and fpkm normalised counts from the filtered output, and check rows match

rawCounts <- counts(analysisObject_sf, normalized = FALSE)
normalisedCounts <- counts(analysisObject_sf, normalized = TRUE)
fpkmNormalisedCounts <- fpkm(analysisObject, robust = TRUE)

## vst transformation 
vstNormalisedCounts <- vst_transform(rawCounts)

## check tables match
if (!identical(rownames(rawCounts), rownames(normalisedCounts))) { stop() }
if (!identical(rownames(fpkmNormalisedCounts), rownames(rawCounts))) { stop() }
if (!identical(rownames(vstNormalisedCounts), rownames(rawCounts))) { stop() }

## filter annotations

filteredGenes <- rownames(normalisedCounts)
filteredGenes[1:5]
filteredAnnocation <- filter(annotationNames, ensemblGeneID %in% filteredGenes)
length(rownames(filteredAnnocation))
if (!identical(rownames(normalisedCounts), filteredAnnocation$ensemblGeneID)) { stop() }

## write data to files

write.csv(rawCounts, file=paste("../output/raw_counts.csv", sep=""), row.names = TRUE)
write.csv(normalisedCounts, file=paste("../output/normalised_counts.csv", sep=""), row.names = TRUE)
write.csv(fpkmNormalisedCounts, file=paste("../output/fpkm_normalised_counts.csv", sep=""), row.names = TRUE)
write.csv(vstNormalisedCounts, file=paste("../output/vst_transform.csv", sep=""), row.names = TRUE)
write.csv(filteredAnnocation, file=paste("../output/annotation.csv", sep=""), row.names = TRUE)

```



