{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "anonymous-tourism",
   "metadata": {},
   "source": [
    "# edinburgh neonatal pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-addition",
   "metadata": {},
   "source": [
    "This file and raw data in github repo here: https://github.com/parkyed/sepsis_ml_omics_msc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-garbage",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "hydraulic-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "from joblib import dump, load\n",
    "from pickle import dump, load\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\")\n",
    "#np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "behavioral-civilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Ed/Documents/GitHub/sepsis_ml_omics_msc'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-connectivity",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "handed-ebony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of columns is:  93\n",
      "The number of row is:  48804\n"
     ]
    }
   ],
   "source": [
    "# import and check data\n",
    "\n",
    "raw_data = pd.read_csv('dataset_edinburgh/input/genomic_data.csv')\n",
    "print('The number of columns is:  '+str(len(raw_data.columns)))\n",
    "print('The number of row is:  '+str(len(raw_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-relations",
   "metadata": {},
   "source": [
    "### Checking for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "rising-bleeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicate rows based on NuID:   0\n",
      "# duplicate rows based on Search_Key:   4671\n",
      "# duplicate rows based on ILMN_Gene:   11000\n",
      "# duplicate rows based on RefSeq_ID:   5742\n",
      "# duplicate rows based on Entrez_Gene_ID:   10897\n",
      "# duplicate rows based on Probe_Id:   1\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of duplicate rows using various columns, NaN values excluded before looking for duplicates.\n",
    "\n",
    "dup_column = ['NuID', 'Search_Key', 'ILMN_Gene', 'RefSeq_ID', 'Entrez_Gene_ID', 'Probe_Id']\n",
    "for column in dup_column:\n",
    "    data = raw_data.dropna(subset=[column])\n",
    "    dup_list = []\n",
    "    for index, value in data.duplicated(subset=[column]).items():\n",
    "        if value == True:\n",
    "            dup_list.append(index)\n",
    "    print(f\"# duplicate rows based on {column}:   \"+str(len(dup_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-generic",
   "metadata": {},
   "source": [
    "### Drop duplicate rows on Probe_Id and transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fuzzy-supply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in dataset:   48802\n",
      "Number of genes in the gene name database:    48802\n",
      "Number of examples in dataset:  63\n",
      "Number of Missing values in dataset:   0\n",
      "The number of features with all zeros is:   0\n",
      "Check indices of df and gene_df match. sum of matching index:   48802\n"
     ]
    }
   ],
   "source": [
    "# reformat data, drop duplicates, transpose, index on probe_id, drop columns with all NaN, drop Fold change\n",
    "\n",
    "# drop duplicate rows based on Probe_Id, and fold change column\n",
    "df = raw_data.drop_duplicates(subset=['Probe_Id'], keep='first')\n",
    "df = df.drop(['Fold change'], axis=1)\n",
    "\n",
    "# split into gene code dataframe, and data set based on unique probes\n",
    "gene_df = df.iloc[:, np.r_[14, 5]]\n",
    "df = df.iloc[:, np.r_[14, 29:92]]\n",
    "\n",
    "# transpose data set and index on probe ID, drop all columns that are all NaN values\n",
    "df = df.transpose()\n",
    "df = df.rename(columns=df.iloc[0]).drop(df.index[0])\n",
    "\n",
    "# identify any columns that are all NaN values, and drop from both data df and gene_df\n",
    "nan_columns = df.columns[df.isna().any()].tolist()\n",
    "df = df.drop(nan_columns, axis=1)\n",
    "gene_df = gene_df[gene_df['Probe_Id'] != nan_columns[0]]\n",
    "print('Number of features in dataset:   '+str(len(df.columns)))\n",
    "print('Number of genes in the gene name database:    '+str(len(gene_df.index)))\n",
    "print('Number of examples in dataset:  '+str(len(df)))\n",
    "print('Number of Missing values in dataset:   '+str(df.isnull().sum().sum()))\n",
    "print('The number of features with all zeros is:   '+str(sum((df == 0).all(axis=0))))\n",
    "print('Check indices of df and gene_df match. sum of matching index:   '+str(sum(df.columns == gene_df['Probe_Id'])))\n",
    "\n",
    "# create copy of the data without patient Inf_075\n",
    "df_no75 = df.drop(['Inf075'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-christianity",
   "metadata": {},
   "source": [
    "### Create labels vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "athletic-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels for both data sets\n",
    "\n",
    "labels = []\n",
    "for item in df.index:\n",
    "    if 'Con' in item:\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "labels_no75 = []\n",
    "for item in df.index:\n",
    "    if item == 'Inf075':\n",
    "        continue\n",
    "    if 'Con' in item:\n",
    "        labels_no75.append(0)\n",
    "    else:\n",
    "        labels_no75.append(1)\n",
    "labels_no75 = np.asarray(labels_no75)\n",
    "\n",
    "# check correct\n",
    "#list(zip(df.index, labels))\n",
    "#list(zip(df_no75.index, labels_no75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "iraqi-pocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sepsis cases:    27\n",
      "Number of control cases:   35\n"
     ]
    }
   ],
   "source": [
    "print('Number of sepsis cases:    '+str(sum(labels_no75)))\n",
    "print('Number of control cases:   '+str(len(labels_no75)-sum(labels_no75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-density",
   "metadata": {},
   "source": [
    "### Standardisation (z-scoring)\n",
    "\n",
    "Data standardised (i.e. z-scored) for the following reasons:\n",
    "- L1 regularisation penalties in logistic regressions assumes data centred at zero and on the same scale\n",
    "- Distance based ML models such as SVM require and assume standardised data, otherwise variables on larger scales disproportionally impact the model\n",
    "- Am using the output coeffiecients from logistic regression as a crude measure of feature importance, and so in order to compare coefficients as a measure of relative importance, variables must be standardised\n",
    "\n",
    "Reference: https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "adolescent-denial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 48802)\n",
      "(62, 48802)\n",
      "(63, 200)\n"
     ]
    }
   ],
   "source": [
    "# standardise by imputing NaN values and using standard scale - z-scoring\n",
    "# note - given imputer not necessary, could move standard scaler into the pipeline for each model\n",
    "\n",
    "def standardise(examples):\n",
    "    scaler = StandardScaler()\n",
    "    examples_scaled = scaler.fit_transform(examples)\n",
    "    return examples_scaled\n",
    "\n",
    "X_df = standardise(df)\n",
    "X_df = pd.DataFrame(X_df, columns=df.columns, index=df.index)\n",
    "print(X_df.shape)\n",
    "\n",
    "# dataset excluding patient 75\n",
    "X_df_no75 = standardise(df_no75)\n",
    "X_df_no75 = pd.DataFrame(X_df_no75, columns=df_no75.columns, index=df_no75.index)\n",
    "print(X_df_no75.shape)\n",
    "\n",
    "# Reduced dataset for code testing\n",
    "X_df_red = X_df.iloc[:, 0:200]\n",
    "print(X_df_red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "approximate-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving pre-processed datasets without ensembl mappings\n",
    "#X_df_no75.to_csv('neonatal_data_processed.csv')\n",
    "#gene_df.to_csv('gene_codes_df.csv')\n",
    "#np.savetxt('labels_no75.csv', labels_no75, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-elite",
   "metadata": {},
   "source": [
    "### Ensembl gene codes filter: illumina -> ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "crucial-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probe_Id</th>\n",
       "      <th>ensemblGeneID</th>\n",
       "      <th>geneName</th>\n",
       "      <th>chromosome_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILMN_2295987</td>\n",
       "      <td>ENSG00000271254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KI270711.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ILMN_2131828</td>\n",
       "      <td>ENSG00000273775</td>\n",
       "      <td>KIR3DL1</td>\n",
       "      <td>CHR_HSCHR19KIR_FH13_A_HAP_CTG3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ILMN_2131828</td>\n",
       "      <td>ENSG00000277272</td>\n",
       "      <td>KIR3DL1</td>\n",
       "      <td>CHR_HSCHR19KIR_T7526_A_HAP_CTG3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ILMN_1772787</td>\n",
       "      <td>ENSG00000274714</td>\n",
       "      <td>KIR2DS4</td>\n",
       "      <td>CHR_HSCHR19KIR_FH06_BA1_HAP_CTG3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ILMN_1772787</td>\n",
       "      <td>ENSG00000274807</td>\n",
       "      <td>KIR2DS4</td>\n",
       "      <td>CHR_HSCHR19KIR_FH15_A_HAP_CTG3_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Probe_Id    ensemblGeneID geneName                     chromosome_name\n",
       "0  ILMN_2295987  ENSG00000271254      NaN                          KI270711.1\n",
       "1  ILMN_2131828  ENSG00000273775  KIR3DL1    CHR_HSCHR19KIR_FH13_A_HAP_CTG3_1\n",
       "2  ILMN_2131828  ENSG00000277272  KIR3DL1   CHR_HSCHR19KIR_T7526_A_HAP_CTG3_1\n",
       "3  ILMN_1772787  ENSG00000274714  KIR2DS4  CHR_HSCHR19KIR_FH06_BA1_HAP_CTG3_1\n",
       "4  ILMN_1772787  ENSG00000274807  KIR2DS4    CHR_HSCHR19KIR_FH15_A_HAP_CTG3_1"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import raw gene code mappings from biomaRt\n",
    "gcMap = pd.read_csv('dataset_edinburgh/illuminaht12v3_ensembl_mapping.csv').drop(['description', 'gene_biotype'], axis=1)\n",
    "gcMap = gcMap.rename(columns={'illumina_humanht_12_v3': 'Probe_Id', 'ensembl_gene_id':'ensemblGeneID', 'external_gene_name':'geneName'})\n",
    "gcMap.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "backed-toner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique probes in illumina dataset:                  48802\n",
      "Number of lines of mappings in the mapping dataset:           44170\n",
      "Number of unique illumina probes mapped to ensembl id:        34232\n",
      "Number of unique ensemble gene_Ids mapped to illumina probe:  27636\n",
      "Number of unique gene_names:                                  22031\n"
     ]
    }
   ],
   "source": [
    "# examine the gene code mappings file\n",
    "print('Number of unique probes in illumina dataset:                  '+str(len(X_df.columns.unique())))\n",
    "print('Number of lines of mappings in the mapping dataset:           '+str(len(gcMap['ensemblGeneID'])))\n",
    "print('Number of unique illumina probes mapped to ensembl id:        '+str(len(gcMap['Probe_Id'].unique())))\n",
    "print('Number of unique ensemble gene_Ids mapped to illumina probe:  '+str(len(gcMap['ensemblGeneID'].unique())))\n",
    "print('Number of unique gene_names:                                  '+str(len(gcMap['geneName'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "favorite-visibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mappings in filtered list:                     39176\n",
      "Number of unique Ilumina Probe_Ids:                      34166\n",
      "Number of unique ensemble gene_Ids mapped to illumina:   24566\n",
      "Number of unique gene_names:                             22002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22002"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## filter out all probes that map to ensembel gene IDs not on the main chromosome (filter out Haplotyptic regions)\n",
    "## source: https://www.researchgate.net/post/How-to-deal-with-multiple-ensemble-IDs-mapping-to-one-gene-symbol-in-a-RNA-Seq-dataset\n",
    "\n",
    "filtered_gcMap = gcMap[~gcMap['chromosome_name'].str.contains('CHR_')]\n",
    "print('Number of mappings in filtered list:                     '+str(len(filtered_gcMap)))\n",
    "print('Number of unique Ilumina Probe_Ids:                      '+str(len(filtered_gcMap['Probe_Id'].unique())))\n",
    "print('Number of unique ensemble gene_Ids mapped to illumina:   '+str(len(filtered_gcMap['ensemblGeneID'].unique())))\n",
    "print('Number of unique gene_names:                             '+str(len(filtered_gcMap['geneName'].unique())))\n",
    "\n",
    "# get index of ilumina probes to filter edinburgh dataset by\n",
    "ilmn_index = filtered_gcMap['Probe_Id'].unique().tolist()\n",
    "\n",
    "# create dictionaries of mapping between gene names to rename dataframes for analysis and visualisation\n",
    "mapping_dict_il_en = filtered_gcMap.set_index('Probe_Id')['ensemblGeneID'].to_dict()\n",
    "\n",
    "\n",
    "# create annotation file by removing duplicate probe IDs in the file\n",
    "e_annotation = filtered_gcMap.set_index('ensemblGeneID').drop('Probe_Id', axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-literacy",
   "metadata": {},
   "source": [
    "### Filter X_df_no75 based on unique ensembl ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "hawaiian-norman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22635"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new dataframe with column names as ensemble_gene_ids\n",
    "e_filtered_X = X_df_no75.loc[:,ilmn_index].rename(columns=mapping_dict_il_en)\n",
    "len(e_filtered_X.columns.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "spectacular-cooking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>index</th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000288683</th>\n",
       "      <th>ENSG00000288684</th>\n",
       "      <th>ENSG00000288690</th>\n",
       "      <th>ENSG00000288694</th>\n",
       "      <th>ENSG00000288702</th>\n",
       "      <th>ENSG00000288705</th>\n",
       "      <th>ENSG00000288709</th>\n",
       "      <th>ENSG00000288710</th>\n",
       "      <th>ENSG00000288722</th>\n",
       "      <th>ENSG00000288725</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Con_001</th>\n",
       "      <td>2.888534</td>\n",
       "      <td>-0.659596</td>\n",
       "      <td>-0.364739</td>\n",
       "      <td>-0.646569</td>\n",
       "      <td>2.499192</td>\n",
       "      <td>-1.272964</td>\n",
       "      <td>-0.207659</td>\n",
       "      <td>-1.141890</td>\n",
       "      <td>0.533802</td>\n",
       "      <td>2.187935</td>\n",
       "      <td>...</td>\n",
       "      <td>1.303396</td>\n",
       "      <td>-0.781858</td>\n",
       "      <td>5.586707</td>\n",
       "      <td>0.255351</td>\n",
       "      <td>0.827552</td>\n",
       "      <td>-0.454670</td>\n",
       "      <td>-0.199624</td>\n",
       "      <td>-0.077013</td>\n",
       "      <td>-0.056568</td>\n",
       "      <td>-0.170078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Con_017</th>\n",
       "      <td>0.984460</td>\n",
       "      <td>-0.082169</td>\n",
       "      <td>0.172782</td>\n",
       "      <td>0.118510</td>\n",
       "      <td>0.920428</td>\n",
       "      <td>-0.707827</td>\n",
       "      <td>-0.238213</td>\n",
       "      <td>0.166939</td>\n",
       "      <td>-0.733598</td>\n",
       "      <td>-0.046384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606745</td>\n",
       "      <td>-0.486954</td>\n",
       "      <td>-0.581603</td>\n",
       "      <td>-1.321316</td>\n",
       "      <td>0.551392</td>\n",
       "      <td>-0.393225</td>\n",
       "      <td>-0.465931</td>\n",
       "      <td>1.441957</td>\n",
       "      <td>-1.369838</td>\n",
       "      <td>0.188739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Con_021</th>\n",
       "      <td>0.904893</td>\n",
       "      <td>-1.344421</td>\n",
       "      <td>1.988677</td>\n",
       "      <td>-0.201075</td>\n",
       "      <td>0.049246</td>\n",
       "      <td>-0.154500</td>\n",
       "      <td>-0.546452</td>\n",
       "      <td>0.741224</td>\n",
       "      <td>-0.446729</td>\n",
       "      <td>-0.181514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.686276</td>\n",
       "      <td>-0.625130</td>\n",
       "      <td>0.347953</td>\n",
       "      <td>0.271238</td>\n",
       "      <td>0.017395</td>\n",
       "      <td>-1.338871</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>0.073144</td>\n",
       "      <td>-0.522460</td>\n",
       "      <td>-0.281323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Con_022b</th>\n",
       "      <td>0.260101</td>\n",
       "      <td>0.763123</td>\n",
       "      <td>1.260019</td>\n",
       "      <td>0.219720</td>\n",
       "      <td>0.206713</td>\n",
       "      <td>-0.292451</td>\n",
       "      <td>-0.228507</td>\n",
       "      <td>-0.184047</td>\n",
       "      <td>-0.801113</td>\n",
       "      <td>-0.121004</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384322</td>\n",
       "      <td>-0.415216</td>\n",
       "      <td>0.069702</td>\n",
       "      <td>-0.588968</td>\n",
       "      <td>-0.512676</td>\n",
       "      <td>0.348604</td>\n",
       "      <td>0.106127</td>\n",
       "      <td>-0.230281</td>\n",
       "      <td>-1.247012</td>\n",
       "      <td>0.263072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Con_028</th>\n",
       "      <td>1.332478</td>\n",
       "      <td>-0.248953</td>\n",
       "      <td>0.463052</td>\n",
       "      <td>0.231828</td>\n",
       "      <td>-0.048916</td>\n",
       "      <td>-0.399417</td>\n",
       "      <td>-0.538397</td>\n",
       "      <td>-0.586701</td>\n",
       "      <td>-1.043378</td>\n",
       "      <td>0.667508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697844</td>\n",
       "      <td>-0.388359</td>\n",
       "      <td>0.579418</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.026556</td>\n",
       "      <td>1.429128</td>\n",
       "      <td>-0.979400</td>\n",
       "      <td>2.160192</td>\n",
       "      <td>-0.941157</td>\n",
       "      <td>0.444008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inf_162a</th>\n",
       "      <td>-1.082590</td>\n",
       "      <td>0.314575</td>\n",
       "      <td>0.919030</td>\n",
       "      <td>-0.326009</td>\n",
       "      <td>-0.558128</td>\n",
       "      <td>0.955597</td>\n",
       "      <td>-0.224085</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>-0.425244</td>\n",
       "      <td>-0.527118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742493</td>\n",
       "      <td>1.123091</td>\n",
       "      <td>-1.591186</td>\n",
       "      <td>1.521072</td>\n",
       "      <td>4.493548</td>\n",
       "      <td>0.853648</td>\n",
       "      <td>0.523193</td>\n",
       "      <td>-0.896365</td>\n",
       "      <td>0.444115</td>\n",
       "      <td>0.661275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inf_164</th>\n",
       "      <td>-0.710751</td>\n",
       "      <td>0.646879</td>\n",
       "      <td>-0.622717</td>\n",
       "      <td>0.155737</td>\n",
       "      <td>-0.871700</td>\n",
       "      <td>0.807105</td>\n",
       "      <td>-0.292683</td>\n",
       "      <td>-1.350358</td>\n",
       "      <td>-0.047524</td>\n",
       "      <td>-0.051068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.672323</td>\n",
       "      <td>1.921045</td>\n",
       "      <td>-1.830039</td>\n",
       "      <td>-0.327956</td>\n",
       "      <td>-0.375250</td>\n",
       "      <td>-1.088597</td>\n",
       "      <td>-0.363532</td>\n",
       "      <td>-0.251101</td>\n",
       "      <td>0.650438</td>\n",
       "      <td>-0.322257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inf_191</th>\n",
       "      <td>-0.755765</td>\n",
       "      <td>-0.668440</td>\n",
       "      <td>-1.653952</td>\n",
       "      <td>-0.973798</td>\n",
       "      <td>-0.815120</td>\n",
       "      <td>0.737404</td>\n",
       "      <td>0.573728</td>\n",
       "      <td>-0.005072</td>\n",
       "      <td>0.789383</td>\n",
       "      <td>0.546675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509075</td>\n",
       "      <td>-1.144437</td>\n",
       "      <td>0.064777</td>\n",
       "      <td>1.132958</td>\n",
       "      <td>0.199320</td>\n",
       "      <td>-0.313797</td>\n",
       "      <td>-0.006638</td>\n",
       "      <td>0.570811</td>\n",
       "      <td>2.247177</td>\n",
       "      <td>-1.273597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inf_198</th>\n",
       "      <td>-0.002000</td>\n",
       "      <td>-0.550934</td>\n",
       "      <td>-0.954246</td>\n",
       "      <td>-0.283290</td>\n",
       "      <td>-1.093244</td>\n",
       "      <td>0.220362</td>\n",
       "      <td>-0.750418</td>\n",
       "      <td>0.258802</td>\n",
       "      <td>2.016188</td>\n",
       "      <td>-0.165000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103453</td>\n",
       "      <td>0.679409</td>\n",
       "      <td>0.383658</td>\n",
       "      <td>-0.109310</td>\n",
       "      <td>0.196702</td>\n",
       "      <td>0.931578</td>\n",
       "      <td>0.254770</td>\n",
       "      <td>-0.992037</td>\n",
       "      <td>2.094401</td>\n",
       "      <td>-0.113327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inf_203</th>\n",
       "      <td>-0.869387</td>\n",
       "      <td>-0.784684</td>\n",
       "      <td>-1.043136</td>\n",
       "      <td>-1.241897</td>\n",
       "      <td>-0.618116</td>\n",
       "      <td>0.905607</td>\n",
       "      <td>-0.219208</td>\n",
       "      <td>0.131570</td>\n",
       "      <td>-0.048910</td>\n",
       "      <td>-0.549701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176998</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>1.371080</td>\n",
       "      <td>-0.897644</td>\n",
       "      <td>-0.860821</td>\n",
       "      <td>-1.340370</td>\n",
       "      <td>0.564142</td>\n",
       "      <td>-0.233782</td>\n",
       "      <td>1.983071</td>\n",
       "      <td>-1.085360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 22635 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "index     ENSG00000000003  ENSG00000000005  ENSG00000000419  ENSG00000000457  \\\n",
       "Con_001          2.888534        -0.659596        -0.364739        -0.646569   \n",
       "Con_017          0.984460        -0.082169         0.172782         0.118510   \n",
       "Con_021          0.904893        -1.344421         1.988677        -0.201075   \n",
       "Con_022b         0.260101         0.763123         1.260019         0.219720   \n",
       "Con_028          1.332478        -0.248953         0.463052         0.231828   \n",
       "...                   ...              ...              ...              ...   \n",
       "Inf_162a        -1.082590         0.314575         0.919030        -0.326009   \n",
       "Inf_164         -0.710751         0.646879        -0.622717         0.155737   \n",
       "Inf_191         -0.755765        -0.668440        -1.653952        -0.973798   \n",
       "Inf_198         -0.002000        -0.550934        -0.954246        -0.283290   \n",
       "Inf_203         -0.869387        -0.784684        -1.043136        -1.241897   \n",
       "\n",
       "index     ENSG00000000460  ENSG00000000938  ENSG00000000971  ENSG00000001036  \\\n",
       "Con_001          2.499192        -1.272964        -0.207659        -1.141890   \n",
       "Con_017          0.920428        -0.707827        -0.238213         0.166939   \n",
       "Con_021          0.049246        -0.154500        -0.546452         0.741224   \n",
       "Con_022b         0.206713        -0.292451        -0.228507        -0.184047   \n",
       "Con_028         -0.048916        -0.399417        -0.538397        -0.586701   \n",
       "...                   ...              ...              ...              ...   \n",
       "Inf_162a        -0.558128         0.955597        -0.224085         0.020868   \n",
       "Inf_164         -0.871700         0.807105        -0.292683        -1.350358   \n",
       "Inf_191         -0.815120         0.737404         0.573728        -0.005072   \n",
       "Inf_198         -1.093244         0.220362        -0.750418         0.258802   \n",
       "Inf_203         -0.618116         0.905607        -0.219208         0.131570   \n",
       "\n",
       "index     ENSG00000001084  ENSG00000001167  ...  ENSG00000288683  \\\n",
       "Con_001          0.533802         2.187935  ...         1.303396   \n",
       "Con_017         -0.733598        -0.046384  ...        -0.606745   \n",
       "Con_021         -0.446729        -0.181514  ...        -0.686276   \n",
       "Con_022b        -0.801113        -0.121004  ...         1.384322   \n",
       "Con_028         -1.043378         0.667508  ...         0.697844   \n",
       "...                   ...              ...  ...              ...   \n",
       "Inf_162a        -0.425244        -0.527118  ...         0.742493   \n",
       "Inf_164         -0.047524        -0.051068  ...        -0.672323   \n",
       "Inf_191          0.789383         0.546675  ...        -0.509075   \n",
       "Inf_198          2.016188        -0.165000  ...         0.103453   \n",
       "Inf_203         -0.048910        -0.549701  ...        -0.176998   \n",
       "\n",
       "index     ENSG00000288684  ENSG00000288690  ENSG00000288694  ENSG00000288702  \\\n",
       "Con_001         -0.781858         5.586707         0.255351         0.827552   \n",
       "Con_017         -0.486954        -0.581603        -1.321316         0.551392   \n",
       "Con_021         -0.625130         0.347953         0.271238         0.017395   \n",
       "Con_022b        -0.415216         0.069702        -0.588968        -0.512676   \n",
       "Con_028         -0.388359         0.579418         0.002660         0.026556   \n",
       "...                   ...              ...              ...              ...   \n",
       "Inf_162a         1.123091        -1.591186         1.521072         4.493548   \n",
       "Inf_164          1.921045        -1.830039        -0.327956        -0.375250   \n",
       "Inf_191         -1.144437         0.064777         1.132958         0.199320   \n",
       "Inf_198          0.679409         0.383658        -0.109310         0.196702   \n",
       "Inf_203          0.002844         1.371080        -0.897644        -0.860821   \n",
       "\n",
       "index     ENSG00000288705  ENSG00000288709  ENSG00000288710  ENSG00000288722  \\\n",
       "Con_001         -0.454670        -0.199624        -0.077013        -0.056568   \n",
       "Con_017         -0.393225        -0.465931         1.441957        -1.369838   \n",
       "Con_021         -1.338871         0.154837         0.073144        -0.522460   \n",
       "Con_022b         0.348604         0.106127        -0.230281        -1.247012   \n",
       "Con_028          1.429128        -0.979400         2.160192        -0.941157   \n",
       "...                   ...              ...              ...              ...   \n",
       "Inf_162a         0.853648         0.523193        -0.896365         0.444115   \n",
       "Inf_164         -1.088597        -0.363532        -0.251101         0.650438   \n",
       "Inf_191         -0.313797        -0.006638         0.570811         2.247177   \n",
       "Inf_198          0.931578         0.254770        -0.992037         2.094401   \n",
       "Inf_203         -1.340370         0.564142        -0.233782         1.983071   \n",
       "\n",
       "index     ENSG00000288725  \n",
       "Con_001         -0.170078  \n",
       "Con_017          0.188739  \n",
       "Con_021         -0.281323  \n",
       "Con_022b         0.263072  \n",
       "Con_028          0.444008  \n",
       "...                   ...  \n",
       "Inf_162a         0.661275  \n",
       "Inf_164         -0.322257  \n",
       "Inf_191         -1.273597  \n",
       "Inf_198         -0.113327  \n",
       "Inf_203         -1.085360  \n",
       "\n",
       "[62 rows x 22635 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decide between duplicate columns - choose the columns with the highest average reads\n",
    "e_filtered_X = e_filtered_X.transpose()\n",
    "e_filtered_X = e_filtered_X.reset_index()\n",
    "e_filtered_X = e_filtered_X.groupby('index').mean()\n",
    "e_filtered_X = e_filtered_X.transpose()\n",
    "e_filtered_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "bizarre-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving pre-processed datasets\n",
    "\n",
    "e_filtered_X.to_csv('dataset_edinburgh/ml_inputs/e_norm_X.csv')\n",
    "e_annotation.to_csv('dataset_edinburgh/ml_inputs/e_annotation.csv')\n",
    "np.savetxt('dataset_edinburgh/ml_inputs/e_y.csv', labels_no75, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-possible",
   "metadata": {},
   "source": [
    "### Analysis of illumina probes from original data set missing from mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "desperate-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of probes in original not mapped to ensemblID:                          14570\n",
      "Number of probe IDs not mapped corresponding to characterised genes in source data:  1353\n"
     ]
    }
   ],
   "source": [
    "# idenify the illumina probe_IDs not mapped to ensembl and whether significant / inconsistent\n",
    "\n",
    "# original set of probes from edinburgh dataset\n",
    "probe_original = X_df.columns.unique()\n",
    "\n",
    "# probe IDs returned by ensemble as mapped\n",
    "probe_ensembl = gcMap['Probe_Id'].unique()\n",
    "\n",
    "# difference bewteen the two sets\n",
    "probe_ID_diff = list(set(probe_original) - set(probe_ensembl))\n",
    "print('Total number of probes in original not mapped to ensemblID:                          '+str(len(probe_ID_diff)))\n",
    "\n",
    "# display the set of missing genes, excluding the uncharacterised genes, starting with HS. and LOC\n",
    "gene_df_filtered = gene_df.set_index('Probe_Id')\n",
    "gene_df_filtered = gene_df_filtered.loc[probe_ID_diff,:]\n",
    "gene_df_filtered = gene_df_filtered[~gene_df_filtered['ILMN_Gene'].str.contains('HS.')]\n",
    "gene_df_filtered = gene_df_filtered[~gene_df_filtered['ILMN_Gene'].str.startswith('LOC')]\n",
    "print('Number of probe IDs not mapped corresponding to characterised genes in source data:  '+str(len(gene_df_filtered.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "micro-realtor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing genes:  {'SLC2A3', 'PDE9A', 'NMT2'}\n"
     ]
    }
   ],
   "source": [
    "# comprare the missing genes with the genes selected by original logistic regression analysis\n",
    "\n",
    "with open('selected_gene_df.pkl', 'rb') as f:\n",
    "    selected_gene_df = pickle.load(f)\n",
    "missing_genes = set(gene_df_filtered['ILMN_Gene'].ravel()).intersection(set(selected_gene_df['ILMN_Gene'].ravel()))\n",
    "print('Missing genes:  '+str(missing_genes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "tribal-bailey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probe_Id</th>\n",
       "      <th>ILMN_Gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>ILMN_1656378</td>\n",
       "      <td>NMT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12281</th>\n",
       "      <td>ILMN_1775708</td>\n",
       "      <td>SLC2A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34814</th>\n",
       "      <td>ILMN_2306540</td>\n",
       "      <td>PDE9A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Probe_Id ILMN_Gene\n",
       "1198   ILMN_1656378      NMT2\n",
       "12281  ILMN_1775708    SLC2A3\n",
       "34814  ILMN_2306540     PDE9A"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the probe_IDs associated with these genes in the two annotation sets\n",
    "# first the original dataset\n",
    "selected_gene_df[selected_gene_df['ILMN_Gene'].isin(['NMT2', 'PDE9A', 'SLC2A3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "median-details",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probe_Id</th>\n",
       "      <th>ensemblGeneID</th>\n",
       "      <th>geneName</th>\n",
       "      <th>chromosome_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>ILMN_1767176</td>\n",
       "      <td>ENSG00000160191</td>\n",
       "      <td>PDE9A</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>ILMN_2062620</td>\n",
       "      <td>ENSG00000152465</td>\n",
       "      <td>NMT2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9709</th>\n",
       "      <td>ILMN_1683063</td>\n",
       "      <td>ENSG00000160191</td>\n",
       "      <td>PDE9A</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31656</th>\n",
       "      <td>ILMN_2306540</td>\n",
       "      <td>ENSG00000160191</td>\n",
       "      <td>PDE9A</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Probe_Id    ensemblGeneID geneName chromosome_name\n",
       "5246   ILMN_1767176  ENSG00000160191    PDE9A              21\n",
       "5404   ILMN_2062620  ENSG00000152465     NMT2              10\n",
       "9709   ILMN_1683063  ENSG00000160191    PDE9A              21\n",
       "31656  ILMN_2306540  ENSG00000160191    PDE9A              21"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not the ensemble mapping\n",
    "gcMap.head()\n",
    "gcMap[gcMap['geneName'].isin(['NMT2', 'PDE9A', 'SLC2A3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "trying-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMT2:True\n",
      "NMT2:True\n",
      "NMT2:True\n",
      "NMT2:True\n"
     ]
    }
   ],
   "source": [
    "# check whether the probes that are mapped to these genes appear in the original dataset:\n",
    "probe_NMT2 = 'ILMN_2062620'\n",
    "print('NMT2:'+str(probe_NMT2 in X_df.columns.unique()))\n",
    "probe_PDE9A = 'ILMN_1767176'\n",
    "print('NMT2:'+str(probe_PDE9A in X_df.columns.unique()))\n",
    "probe_PDE9A_2 = 'ILMN_1683063'\n",
    "print('NMT2:'+str(probe_PDE9A_2 in X_df.columns.unique()))\n",
    "probe_PDE9A_3 = 'ILMN_2306540'\n",
    "print('NMT2:'+str(probe_PDE9A_3 in X_df.columns.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-forest",
   "metadata": {},
   "source": [
    "Conclusion: probe_Ids associated with these three genes are not mapped to these genes in the dataset. The probes that are now mapped to these genes were in the dataset, but were not picked out by the logistic regression model\n",
    "\n",
    "There is no probe in this illumina microarray that is now mapped to SLC2A3 in ensembl, indicating that this array may not be able to detect SLC2A3 based on the latest mappings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-titanium",
   "metadata": {},
   "source": [
    "### Not used: previous attempt at merging gene annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "lyric-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the gene code mapping with the original gene codes file\n",
    "\n",
    "#gene_df_merged = pd.merge(gene_df, gcMap, how='left', on='Probe_Id')\n",
    "\n",
    "## check that all probes in the raw data set remain in the merged gene annotation, and in the same order:\n",
    "\n",
    "#sum(gene_df_merged['Probe_Id'].unique() != X_df.columns)\n",
    "\n",
    "## saved merged gene dataset\n",
    "#gene_df_merged.to_csv('gene_codes_merged.csv')\n",
    "\n",
    "#filtered_gdfm = gene_df_merged[gene_df_merged['ensembl_gene_id'].isnull()]\n",
    "#print(len(filtered_gdfm))\n",
    "#filtered_gdfm = filtered_gdfm[~filtered_gdfm['ILMN_Gene'].str.contains('HS.')]\n",
    "#filtered_gdfm = filtered_gdfm[~filtered_gdfm['ILMN_Gene'].str.contains('LOC')]\n",
    "#filtered_gdfm\n",
    "\n",
    "# use selected index to reduce the gene dataframe to the selected genes, with codes that map across datasets\n",
    "# need to make Probe_Id the index, so can use with the merged dataframe.\n",
    "\n",
    "# read in merged gene codes data for illumina\n",
    "#gene_df_merged = pd.read_csv('gene_codes_merged.csv', index_col=0).set_index('Probe_Id')\n",
    "\n",
    "# pull out the illumina Probe_Id to use as index filter\n",
    "#gene_index_ilmn = selected_gene_df['Probe_Id'].tolist()\n",
    "\n",
    "#p_missing_probe = 'ENSG00000283060'\n",
    "\n",
    "# filter the gene dataframe on the selected genes\n",
    "#gene_signature_df = gene_df_merged.loc[gene_index_ilmn, :].dropna(axis=0, how='any')  # for now, remove nan values\n",
    "#gene_signature_df = gene_signature_df.reset_index(inplace=False).set_index('ensembl_gene_id')\n",
    "\n",
    "# eliminate ensemble_IDs missing from pearth dataset\n",
    "\n",
    "#gene_signature_df = gene_signature_df.drop(p_missing_probe)\n",
    "#gene_signature_df = gene_signature_df.reset_index(inplace=False)\n",
    "#print(gene_signature_df)\n",
    "\n",
    "#gene_signature_ensembl = gene_signature_df['ensembl_gene_id'].tolist()\n",
    "#gene_signature_ilmn = gene_signature_df['Probe_Id'].tolist()\n",
    "#print(gene_signature_ilmn,gene_signature_ensembl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
