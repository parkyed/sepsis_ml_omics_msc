{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "anonymous-tourism",
   "metadata": {},
   "source": [
    "# pearth neonatal dataset: pre-processing for ml input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-garbage",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "hydraulic-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from joblib import dump, load\n",
    "from pickle import dump, load\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\")\n",
    "#np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "behavioral-civilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Ed/Documents/GitHub/sepsis_ml_omics_msc'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-connectivity",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "handed-ebony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised counts data shape:  (60251, 101)\n",
      "vst counts data shape:  (60251, 101)\n",
      "fpkm counts data shape:  (60251, 101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>10005_sepsis</th>\n",
       "      <th>10006_NOLOS</th>\n",
       "      <th>10009_sepsis</th>\n",
       "      <th>10015_NOLOS</th>\n",
       "      <th>10017_NOLOS</th>\n",
       "      <th>10018_sepsis</th>\n",
       "      <th>10021_NOLOS</th>\n",
       "      <th>10022_sepsis</th>\n",
       "      <th>10029_NOLOS</th>\n",
       "      <th>...</th>\n",
       "      <th>10501_Index</th>\n",
       "      <th>10501_NOLOS</th>\n",
       "      <th>10506_Index</th>\n",
       "      <th>10506_sepsis</th>\n",
       "      <th>10509_Index</th>\n",
       "      <th>10509_NOLOS</th>\n",
       "      <th>10510_Index</th>\n",
       "      <th>10514_Index</th>\n",
       "      <th>10515_Index</th>\n",
       "      <th>10517_NOLOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>13.718303</td>\n",
       "      <td>20.014954</td>\n",
       "      <td>5.999820</td>\n",
       "      <td>13.357729</td>\n",
       "      <td>3.549098</td>\n",
       "      <td>5.292374</td>\n",
       "      <td>19.763132</td>\n",
       "      <td>13.186977</td>\n",
       "      <td>1.713466</td>\n",
       "      <td>...</td>\n",
       "      <td>10.885164</td>\n",
       "      <td>11.766278</td>\n",
       "      <td>16.609504</td>\n",
       "      <td>9.207933</td>\n",
       "      <td>5.498076</td>\n",
       "      <td>17.021216</td>\n",
       "      <td>6.891690</td>\n",
       "      <td>33.035014</td>\n",
       "      <td>26.139871</td>\n",
       "      <td>7.548518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.586448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.277654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.749038</td>\n",
       "      <td>0.362154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.006469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>244.969689</td>\n",
       "      <td>245.600166</td>\n",
       "      <td>205.993832</td>\n",
       "      <td>211.052112</td>\n",
       "      <td>209.396780</td>\n",
       "      <td>238.156820</td>\n",
       "      <td>216.955269</td>\n",
       "      <td>235.481738</td>\n",
       "      <td>193.621672</td>\n",
       "      <td>...</td>\n",
       "      <td>214.478037</td>\n",
       "      <td>227.651909</td>\n",
       "      <td>181.426895</td>\n",
       "      <td>233.651308</td>\n",
       "      <td>335.382662</td>\n",
       "      <td>187.595531</td>\n",
       "      <td>242.501345</td>\n",
       "      <td>214.066891</td>\n",
       "      <td>191.091470</td>\n",
       "      <td>208.339102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000000457</td>\n",
       "      <td>503.657681</td>\n",
       "      <td>407.804689</td>\n",
       "      <td>653.980419</td>\n",
       "      <td>508.929459</td>\n",
       "      <td>498.056749</td>\n",
       "      <td>522.621912</td>\n",
       "      <td>426.005286</td>\n",
       "      <td>269.391108</td>\n",
       "      <td>419.799199</td>\n",
       "      <td>...</td>\n",
       "      <td>448.307475</td>\n",
       "      <td>477.301643</td>\n",
       "      <td>389.684528</td>\n",
       "      <td>494.926417</td>\n",
       "      <td>503.073993</td>\n",
       "      <td>410.682109</td>\n",
       "      <td>477.249539</td>\n",
       "      <td>347.528348</td>\n",
       "      <td>411.026936</td>\n",
       "      <td>468.008127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>263.587386</td>\n",
       "      <td>240.596427</td>\n",
       "      <td>321.990359</td>\n",
       "      <td>466.184728</td>\n",
       "      <td>248.436858</td>\n",
       "      <td>283.141998</td>\n",
       "      <td>313.135844</td>\n",
       "      <td>244.901007</td>\n",
       "      <td>289.575774</td>\n",
       "      <td>...</td>\n",
       "      <td>303.978270</td>\n",
       "      <td>288.018033</td>\n",
       "      <td>269.585034</td>\n",
       "      <td>253.218167</td>\n",
       "      <td>228.170172</td>\n",
       "      <td>231.416109</td>\n",
       "      <td>289.450984</td>\n",
       "      <td>278.815518</td>\n",
       "      <td>306.467452</td>\n",
       "      <td>242.055816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  10005_sepsis  10006_NOLOS  10009_sepsis  10015_NOLOS  \\\n",
       "0  ENSG00000000003     13.718303    20.014954      5.999820    13.357729   \n",
       "1  ENSG00000000005      0.000000     0.000000      0.000000     0.000000   \n",
       "2  ENSG00000000419    244.969689   245.600166    205.993832   211.052112   \n",
       "3  ENSG00000000457    503.657681   407.804689    653.980419   508.929459   \n",
       "4  ENSG00000000460    263.587386   240.596427    321.990359   466.184728   \n",
       "\n",
       "   10017_NOLOS  10018_sepsis  10021_NOLOS  10022_sepsis  10029_NOLOS  ...  \\\n",
       "0     3.549098      5.292374    19.763132     13.186977     1.713466  ...   \n",
       "1     0.000000      0.000000     0.000000     71.586448     0.000000  ...   \n",
       "2   209.396780    238.156820   216.955269    235.481738   193.621672  ...   \n",
       "3   498.056749    522.621912   426.005286    269.391108   419.799199  ...   \n",
       "4   248.436858    283.141998   313.135844    244.901007   289.575774  ...   \n",
       "\n",
       "   10501_Index  10501_NOLOS  10506_Index  10506_sepsis  10509_Index  \\\n",
       "0    10.885164    11.766278    16.609504      9.207933     5.498076   \n",
       "1     0.000000     0.000000     1.277654      0.000000     2.749038   \n",
       "2   214.478037   227.651909   181.426895    233.651308   335.382662   \n",
       "3   448.307475   477.301643   389.684528    494.926417   503.073993   \n",
       "4   303.978270   288.018033   269.585034    253.218167   228.170172   \n",
       "\n",
       "   10509_NOLOS  10510_Index  10514_Index  10515_Index  10517_NOLOS  \n",
       "0    17.021216     6.891690    33.035014    26.139871     7.548518  \n",
       "1     0.362154     0.000000     0.000000     0.000000     1.006469  \n",
       "2   187.595531   242.501345   214.066891   191.091470   208.339102  \n",
       "3   410.682109   477.249539   347.528348   411.026936   468.008127  \n",
       "4   231.416109   289.450984   278.815518   306.467452   242.055816  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and check data\n",
    "\n",
    "# alternative X matrices\n",
    "normalisedCounts = pd.read_csv('dataset_pearth/an0304/output/normalised_counts.csv') #, index_col=0)\n",
    "vstNormalisedCounts = pd.read_csv('dataset_pearth/an0304/output/vst_transform.csv') #, index_col=0)\n",
    "fpkmNormalisedCounts = pd.read_csv('dataset_pearth/an0304/output/fpkm_normalised_counts.csv') #, index_col=0)\n",
    "\n",
    "# annotation and class labels\n",
    "annotation = pd.read_csv('dataset_pearth/an0304/output/annotation.csv', index_col=0)\n",
    "labels_data = pd.read_csv('dataset_pearth/an0304/resources/targets.csv', index_col=0)\n",
    "\n",
    "# check\n",
    "print('Normalised counts data shape:  '+str(normalisedCounts.shape))\n",
    "print('vst counts data shape:  '+str(vstNormalisedCounts.shape))\n",
    "print('fpkm counts data shape:  '+str(fpkmNormalisedCounts.shape))\n",
    "normalisedCounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "elementary-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of examples in the filtered data set is:    78\n"
     ]
    }
   ],
   "source": [
    "# import class groupings\n",
    "targets = pd.read_csv('dataset_pearth/an0304/resources/targets.csv', index_col=0)\n",
    "\n",
    "# create index based on analysisID for the examples in the sepsis or control groups. (P-LOS and contaminant excluded)\n",
    "index_test = targets.index[targets['sampleGroupML2'].isin(['sepsis', 'control'])]\n",
    "\n",
    "# filter the targets file by the index\n",
    "targets_filtered = targets.loc[index_test,:]\n",
    "print('The number of examples in the filtered data set is:    '+str(len(targets_filtered['sampleGroupML2'].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-mustang",
   "metadata": {},
   "source": [
    "### Pre-process X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "nutritional-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing function for all the perth datasets types\n",
    "\n",
    "def pre_process_X(raw_data):\n",
    "    \n",
    "    ''' dataframe -> datafram\n",
    "    Input dataframe of normalised rnaseq data, transformed and z-scored\n",
    "    '''\n",
    "    # rename first column to ensembleGeneID and drop any duplicate rows based on this column\n",
    "    df = raw_data.rename({\"Unnamed: 0\": \"ensemblGeneID\"}, axis=1).drop_duplicates(subset=[\"ensemblGeneID\"], keep='first')\n",
    "    \n",
    "    # transpose the dataframe so genes are the columns\n",
    "    df = df.transpose()\n",
    "    \n",
    "    # set the column names to first row, i.e ensembleGeneID, in the transposed frame\n",
    "    df = df.rename(columns=df.iloc[0]).drop(df.index[0])\n",
    "    \n",
    "    # drop columns containing any NaN values\n",
    "    nan_columns = df.columns[df.isna().any()].tolist()\n",
    "    df = df.drop(nan_columns, axis=1)\n",
    "    \n",
    "    # z-score the data\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    df = pd.DataFrame(df_scaled, columns=df.columns, index=df.index)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "seventh-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process each matrix and filter based on index\n",
    "\n",
    "p_norm_X = pre_process_X(normalisedCounts).loc[index_test,:]\n",
    "p_vst_X = pre_process_X(vstNormalisedCounts).loc[index_test,:]\n",
    "p_fpkm_X = pre_process_X(fpkmNormalisedCounts).loc[index_test,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-library",
   "metadata": {},
   "source": [
    "### Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "minute-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter labels data to cross ref\n",
    "labels_data = labels_data.loc[index_test,:]\n",
    "\n",
    "# create labels vector\n",
    "labels = []\n",
    "for item in p_norm_X.index:\n",
    "    if 'sepsis' in item:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "# check correct\n",
    "# list(zip(labels_data['sampleGroupML'], p_norm_X.index, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "elder-japanese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapre of dataset:   (78, 60251)\n",
      "Number of Missing values in dataset:   0\n",
      "The number of features with all zeros is:   0\n",
      "Check data and annotation indices match:   78\n"
     ]
    }
   ],
   "source": [
    "# get check output dimensions\n",
    "print('Shapre of dataset:   '+str(p_norm_X.shape))\n",
    "print('Number of Missing values in dataset:   '+str(p_norm_X.isnull().sum().sum()))\n",
    "print('The number of features with all zeros is:   '+str(sum((p_norm_X == 0).all(axis=0))))\n",
    "print('Check data and annotation indices match:   '+str(sum(p_norm_X.index == labels_data.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-calendar",
   "metadata": {},
   "source": [
    "### Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "approximate-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving pre-processed datasets\n",
    "\n",
    "p_norm_X.to_csv('dataset_pearth/an0304/ml_inputs/p_norm_X.csv')\n",
    "p_vst_X.to_csv('dataset_pearth/an0304/ml_inputs/p_vst_X.csv')\n",
    "p_fpkm_X.to_csv('dataset_pearth/an0304/ml_inputs/p_fpkm_X.csv')\n",
    "annotation.to_csv('dataset_pearth/an0304/ml_inputs/pearth_annotation.csv')\n",
    "np.savetxt('dataset_pearth/an0304/ml_inputs/pearth_y.csv', labels, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "falling-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check whether two data frames are the same. Number of matches false should equal zero\n",
    "#(df1 == df2)[(df1 == df2)==False].count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-basket",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
